{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6626821-4db1-47bc-8952-8219d9556426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9052d3e-b97d-448d-8d20-69b2772ad5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531e2ff-02f8-4bb9-8d0d-629de241cb8c",
   "metadata": {},
   "source": [
    "# Install and load all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b233ca7a-64b9-4799-b02f-0650033bed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastai.vision.all import *\n",
    "from ml_utils import *\n",
    "from skimage.measure import label,regionprops,find_contours\n",
    "from evalutils import DetectionAlgorithm\n",
    "from evalutils.validators import (UniquePathIndicesValidator, DataFrameValidator)\n",
    "from evalutils.exceptions import ValidationError\n",
    "from typing import (Tuple)\n",
    "from typing import Dict\n",
    "from pandas import DataFrame\n",
    "import json, random, SimpleITK, gc, cv2, os, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbb1c8c2-a278-4a9c-be23-2f2f723fc47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import nb_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0822e98e-a00b-458c-9f6a-3613a6ec71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "execute_in_docker = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a4e8f9-293d-4282-af44-9760cf4a90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def fname_has_int(f):\n",
    "    r = re.compile(r\"\\D*((?:\\d+\\.?)+)\\D*\")\n",
    "    m = r.search(f.stem)\n",
    "    if m is not None:\n",
    "        print('There is int in the file name so no need to change file name.')\n",
    "        return True\n",
    "    else:\n",
    "        print('Add int in the file name as currently there is no int in the file name.')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64f6f805-1cfe-4892-b59e-04723a52f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class VideoLoader():\n",
    "    def load(self, *, fname):\n",
    "        path = Path(fname).absolute()\n",
    "        \n",
    "        print(f'Loading file: {str(path)}')\n",
    "\n",
    "        if not path.is_file():\n",
    "            raise IOError(\n",
    "                f\"Could not load {fname} using {self.__class__.__qualname__}.\"\n",
    "            )\n",
    "        print (f'File {fname} found...')\n",
    "        \n",
    "        if not fname_has_int(path):\n",
    "            old_file = path\n",
    "            new_file = os.path.join(old_file.absolute().parent, str(old_file.stem)+'_1'+str(old_file.suffix))\n",
    "            print(f'Old name: {old_file}')\n",
    "            print(f'New name: {new_file}')\n",
    "            os.rename(old_file, new_file)\n",
    "            fname=new_file\n",
    "            print(f'The file name is changed to contain an integer.')\n",
    "        \n",
    "        return [{\"path\": fname}]\n",
    "\n",
    "\n",
    "    # only path valid\n",
    "    def hash_video(self, input_video):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9142a2e-75d0-4f02-92ae-3ceaa27dcd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class UniqueVideoValidator(DataFrameValidator):\n",
    "    \"\"\"\n",
    "    Validates that each video in the set is unique\n",
    "    \"\"\"\n",
    "\n",
    "    def validate(self, *, df: DataFrame):\n",
    "        try:\n",
    "            hashes = df[\"video\"]\n",
    "        except KeyError:\n",
    "            raise ValidationError(\"Column `video` not found in DataFrame.\")\n",
    "\n",
    "        if len(set(hashes)) != len(hashes):\n",
    "            raise ValidationError(\n",
    "                \"The videos are not unique, please submit a unique video for \"\n",
    "                \"each case.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3305081-6d9a-4d24-9011-48aeb16ccbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: /home/bilal/mlworks/surgtoolloc2/test/input/vid_short_1.mp4\n",
      "File test/input/vid_short_1.mp4 found...\n",
      "There is int in the file name so no need to change file name.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'path': 'test/input/vid_short_1.mp4'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = get_files('./test/input/')\n",
    "fs[0]\n",
    "VideoLoader().load(fname=str(fs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8b05c36-ad78-4d2d-b2c8-2a3182257cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "class Surgtoolloc_det(DetectionAlgorithm):\n",
    "    def __init__(self):\n",
    "        print(' ')\n",
    "        print('TeamZERO prediction engine has started!.')\n",
    "        print('Surgtoolloc_det.__init__() entered.')\n",
    "        super().__init__(\n",
    "            index_key='input_video',\n",
    "            file_loaders={'input_video': VideoLoader()},\n",
    "            input_path=Path(\"/input/\") if execute_in_docker else Path(\"./test/input/\"),\n",
    "            output_file=Path(\"/output/surgical-tool-presence.json\") if execute_in_docker else Path(\n",
    "                \"./test/output/surgical-tool-presence.json\"),\n",
    "            validators=dict(input_video=(UniquePathIndicesValidator(),)),\n",
    "        )\n",
    "        \n",
    "        # loading ensemble learner\n",
    "        print('-Loading models & tools dictionary.')\n",
    "        self.cpu=False\n",
    "        ensem_path=Path('/opt/algorithm/models') if execute_in_docker else Path(\"test/models\")\n",
    "\n",
    "        self.ensem_learner=[load_learner(m, cpu=self.cpu) for m in ensem_path.ls() if m.suffix=='.pkl']\n",
    "        print(f'-{len(self.ensem_learner)} mutli-class classification models have been detected & loaded.')\n",
    "\n",
    "        self.tool_list = [\"needle_driver\",\n",
    "                          \"monopolar_curved_scissor\",\n",
    "                          \"force_bipolar\",\n",
    "                          \"clip_applier\",\n",
    "                          \"tip_up_fenestrated_grasper\",\n",
    "                          \"cadiere_forceps\",\n",
    "                          \"bipolar_forceps\",\n",
    "                          \"vessel_sealer\",\n",
    "                          \"suction_irrigator\",\n",
    "                          \"bipolar_dissector\",\n",
    "                          \"prograsp_forceps\",\n",
    "                          \"stapler\",\n",
    "                          \"permanent_cautery_hook_spatula\",\n",
    "                          \"grasping_retractor\"]\n",
    "        print('-Tools dictionary loaded!.')\n",
    "        print('Surgtoolloc_det.__init__() exited.')\n",
    "        print(' ')\n",
    "        \n",
    "    def extract_images(self, video_file):     \n",
    "        \n",
    "        print('Surgtoolloc_det.extract_images(): entered.')\n",
    "        # start the loop\n",
    "        count = 0\n",
    "        dst=Path('/images') if execute_in_docker else Path(\"./test/images/\")\n",
    "        for i in get_image_files(dst): os.remove(i) \n",
    "        \n",
    "        # read the video file  \n",
    "        print(f'-{str(video_file)} ready for frame extraction.')\n",
    "        cap = cv2.VideoCapture(str(video_file))\n",
    "        \n",
    "        while True:\n",
    "            is_read, f = cap.read()\n",
    "            if not is_read:\n",
    "                # break out of the loop if there are no frames to read\n",
    "                break\n",
    "            name = str(dst/f'im_{count}.jpg')\n",
    "            cv2.imwrite(name,f)\n",
    "            count+=1\n",
    "        cap.release()\n",
    "        print(f'-{len(get_image_files(dst))} images from {video_file} are extracted in {dst} folder. Extraction done!.')\n",
    "        print('Surgtoolloc_det.extract_images(): exited.')\n",
    "        \n",
    "    def tool_detect_json_sample(self):\n",
    "        # single output dict\n",
    "        slice_dict = {\"slice_nr\": 1}\n",
    "        tool_boolean_dict = {i: False for i in self.tool_list}\n",
    "        single_output_dict = {**slice_dict, **tool_boolean_dict}\n",
    "        return single_output_dict\n",
    "        \n",
    "    def process_case(self, *, idx, case):\n",
    "        print('Surgtoolloc_det.process_case() entered')\n",
    "        # Input video would return the collection of all frames (cap object)\n",
    "        print(case)\n",
    "        input_video_file_path = case #VideoLoader.load(case)\n",
    "        scored_candidates = self.predict(case['path']) #video file > load evalutils.py\n",
    "\n",
    "        # return\n",
    "        # Write resulting candidates to result.json for this case\n",
    "        print('Surgtoolloc_det.process_case() exited.')\n",
    "        return scored_candidates\n",
    "\n",
    "    def save(self):\n",
    "        print('Surgtoolloc_det.save() entered')\n",
    "        with open(str(self._output_file), \"w\") as f:\n",
    "            json.dump(self._case_results[0], f)\n",
    "        \n",
    "        print('-file saved')\n",
    "        print('Surgtoolloc_det.save() exited')\n",
    "        \n",
    "    def predict(self, fname) -> Dict:\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        fname -> video file path\n",
    "        \n",
    "        Output:\n",
    "        tools -> list of prediction dictionaries (per frame) in the correct format as described in documentation \n",
    "        \"\"\"\n",
    "        print('Surgtoolloc_det.predict() entered')\n",
    "        print(f'Processing {str(fname)} for tools presence detection')\n",
    "        print(' ')\n",
    "        self.extract_images(fname)\n",
    "        print(' ')\n",
    "\n",
    "        images_dir = Path('/images') if execute_in_docker else Path(\"./test/images/\")\n",
    "        fs=get_image_files(images_dir)\n",
    "        \n",
    "        num_frames = len(fs)\n",
    "        \n",
    "        print(' ')\n",
    "        print(f'-Tools presence detection task started.')\n",
    "\n",
    "        # generate output json\n",
    "        all_frames_predicted_outputs = []\n",
    "        all_undefined_tools=[]\n",
    "        \n",
    "        tta_res=[]\n",
    "        prs_items=[]\n",
    "        for learn in self.ensem_learner:\n",
    "            learn.dls.bs=16\n",
    "            learn.dls.n_workers=2\n",
    "            tta_res.append(learn.tta(dl=learn.dls.test_dl(fs)))\n",
    "            if len(prs_items)<1:\n",
    "                prs_items=learn.dl.items\n",
    "            if not self.cpu:\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        print(f'-Predictions from all models in the ensemble learner are obtained!.')\n",
    "        tta_prs=first(zip(*tta_res))\n",
    "        tta_prs+=tta_prs[:1]\n",
    "        tta_prs=torch.stack(tta_prs)\n",
    "\n",
    "        lbls=[]\n",
    "        for i in range(len(c)):\n",
    "            arm_preds = tta_prs[:,:,cfg(i):cfg(i+1)].mean(0);\n",
    "            arm_idxs = arm_preds.argmax(dim=1)\n",
    "            arm_vocab = np.array(vocab[i])\n",
    "            lbls.append(arm_vocab[arm_idxs])\n",
    "\n",
    "        for usm1,usm2,usm3,usm4,f in zip(lbls[0],lbls[1],lbls[2],lbls[3],prs_items):\n",
    "            frame_dict=self.tool_detect_json_sample()\n",
    "            frame_dict['slice_nr']=int(f.stem.replace(\"im_\",\"\"))\n",
    "            frame_dict[usm1]=True if usm1 in frame_dict.keys() else all_undefined_tools.append(usm1)\n",
    "            frame_dict[usm2]=True if usm2 in frame_dict.keys() else all_undefined_tools.append(usm2)\n",
    "            frame_dict[usm3]=True if usm3 in frame_dict.keys() else all_undefined_tools.append(usm3)\n",
    "            frame_dict[usm4]=True if usm4 in frame_dict.keys() else all_undefined_tools.append(usm4)\n",
    "            frame_dict.pop(\"nan\", None)\n",
    "            frame_dict.pop(\"blank\", None)\n",
    "            frame_dict.pop(\"out_of_view\", None)\n",
    "            all_frames_predicted_outputs.append(frame_dict) \n",
    "        \n",
    "        print(f'-Translation of class probabilities to tool labels is done!.')\n",
    "        \n",
    "        print(f'-Following tools remained unaccounted for: {set(all_undefined_tools)}. Please ensure if it is OK to skip these tools from the output.')\n",
    "        tools=sorted(all_frames_predicted_outputs, key=lambda d: d['slice_nr']) \n",
    "\n",
    "        print(f'-Output JSON file generated & returned!.')\n",
    "        \n",
    "        print(' ')\n",
    "        \n",
    "        print(f'{fname} has been successfully processed!.')\n",
    "        print('Surgtoolloc_det.predict() exited')\n",
    "\n",
    "        print(' ')\n",
    "        return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2f0d844-55ff-4905-99f1-b442b17669a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "TeamZERO prediction engine has started!.\n",
      "Surgtoolloc_det.__init__() entered.\n",
      "-Loading models & tools dictionary.\n",
      "-3 mutli-class classification models have been detected & loaded.\n",
      "-Tools dictionary loaded!.\n",
      "Surgtoolloc_det.__init__() exited.\n",
      " \n",
      "Surgtoolloc_det.predict() entered\n",
      "Processing test/input/vid_short_1.mp4 for tools presence detection\n",
      " \n",
      "Surgtoolloc_det.extract_images(): entered.\n",
      "-test/input/vid_short_1.mp4 ready for frame extraction.\n",
      "-60 images from test/input/vid_short_1.mp4 are extracted in test/images folder. Extraction done!.\n",
      "Surgtoolloc_det.extract_images(): exited.\n",
      " \n",
      " \n",
      "-Tools presence detection task started.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Predictions from all models in the ensemble learner are obtained!.\n",
      "-Translation of class probabilities to tool labels is done!.\n",
      "-Following tools remained unaccounted for: {'nan'}. Please ensure if it is OK to skip these tools from the output.\n",
      "-Output JSON file generated & returned!.\n",
      " \n",
      "test/input/vid_short_1.mp4 has been successfully processed!.\n",
      "Surgtoolloc_det.predict() exited\n",
      " \n",
      "CPU times: user 1min 3s, sys: 43.3 s, total: 1min 46s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%time pred_json=Surgtoolloc_det().predict(str(fs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae53d8cb-81c8-460b-9d6e-61edad49060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "TeamZERO prediction engine has started!.\n",
      "Surgtoolloc_det.__init__() entered.\n",
      "-Loading models & tools dictionary.\n",
      "-3 mutli-class classification models have been detected & loaded.\n",
      "-Tools dictionary loaded!.\n",
      "Surgtoolloc_det.__init__() exited.\n",
      " \n",
      "Key and File Loader\n",
      "input_video <__main__.VideoLoader object at 0x7f24dbf52b50>\n",
      "filter: None\n",
      "Loading file: /home/bilal/mlworks/surgtoolloc2/test/input/vid_short_1.mp4\n",
      "File test/input/vid_short_1.mp4 found...\n",
      "There is int in the file name so no need to change file name.\n",
      "test/input <__main__.VideoLoader object at 0x7f24dbf52b50> None\n",
      "Inside the validate()\n",
      "['input_video']\n",
      "dict_keys(['input_video'])\n",
      "input_video\n",
      "input_video                          path\n",
      "0  test/input/vid_short_1.mp4\n",
      "Inside process_cases()...\n",
      "Surgtoolloc_det.process_case() entered\n",
      "path    test/input/vid_short_1.mp4\n",
      "Name: 0, dtype: object\n",
      "Surgtoolloc_det.predict() entered\n",
      "Processing test/input/vid_short_1.mp4 for tools presence detection\n",
      " \n",
      "Surgtoolloc_det.extract_images(): entered.\n",
      "-test/input/vid_short_1.mp4 ready for frame extraction.\n",
      "-60 images from test/input/vid_short_1.mp4 are extracted in test/images folder. Extraction done!.\n",
      "Surgtoolloc_det.extract_images(): exited.\n",
      " \n",
      " \n",
      "-Tools presence detection task started.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Predictions from all models in the ensemble learner are obtained!.\n",
      "-Translation of class probabilities to tool labels is done!.\n",
      "-Following tools remained unaccounted for: {'nan'}. Please ensure if it is OK to skip these tools from the output.\n",
      "-Output JSON file generated & returned!.\n",
      " \n",
      "test/input/vid_short_1.mp4 has been successfully processed!.\n",
      "Surgtoolloc_det.predict() exited\n",
      " \n",
      "Surgtoolloc_det.process_case() exited.\n",
      "Surgtoolloc_det.save() entered\n",
      "-file saved\n",
      "Surgtoolloc_det.save() exited\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "if __name__ == \"__main__\":\n",
    "    Surgtoolloc_det().process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fdaf8bd-d2f6-4730-9d31-306a200e6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_export('09_inference.ipynb', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "082be8cd-a9f7-4c1f-a2e7-ae0d7edd413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_export('09_inference.ipynb', '/home/bilal/mlworks/surgtoolloc2022-category-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdc11bf0-e08f-42d7-83d4-0132f5358168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "TeamZERO prediction engine has started!.\n",
      "Surgtoolloc_det.__init__() entered.\n",
      "-Loading models & tools dictionary.\n",
      "-3 mutli-class classification models have been detected & loaded.\n",
      "-Tools dictionary loaded!.\n",
      "Surgtoolloc_det.__init__() exited.\n",
      " \n",
      "Key and File Loader\n",
      "input_video <__main__.VideoLoader object at 0x7fc67fc94280>\n",
      "filter: None\n",
      "Loading file: /home/bilal/mlworks/surgtoolloc2/test/input/vid_short_1.mp4\n",
      "File test/input/vid_short_1.mp4 found...\n",
      "There is int in the file name so no need to change file name.\n",
      "test/input <__main__.VideoLoader object at 0x7fc67fc94280> None\n",
      "Inside the validate()\n",
      "['input_video']\n",
      "dict_keys(['input_video'])\n",
      "input_video\n",
      "input_video                          path\n",
      "0  test/input/vid_short_1.mp4\n",
      "Inside process_cases()...\n",
      "Surgtoolloc_det.process_case() entered\n",
      "path    test/input/vid_short_1.mp4\n",
      "Name: 0, dtype: object\n",
      "Surgtoolloc_det.predict() entered\n",
      "Processing test/input/vid_short_1.mp4 for tools presence detection\n",
      " \n",
      "Surgtoolloc_det.extract_images(): entered.\n",
      "-test/input/vid_short_1.mp4 ready for frame extraction.\n",
      "-60 images from test/input/vid_short_1.mp4 are extracted in test/images folder. Extraction done!.\n",
      "Surgtoolloc_det.extract_images(): exited.\n",
      " \n",
      " \n",
      "-Tools presence detection task started.\n",
      "epoch     train_loss  valid_loss  usm1_loss  usm2_loss  usm3_loss  usm4_loss  usm1_err  usm2_err  usm3_err  usm4_err  combo_err  time    \n",
      "epoch     train_loss  valid_loss  usm1_loss  usm2_loss  usm3_loss  usm4_loss  usm1_err  usm2_err  usm3_err  usm4_err  combo_err  time    \n",
      "epoch     train_loss  valid_loss  usm1_loss  usm2_loss  usm3_loss  usm4_loss  usm1_err  usm2_err  usm3_err  usm4_err  combo_err  time    \n",
      "-Predictions from all models in the ensemble learner are obtained!.\n",
      "-Translation of class probabilities to tool labels is done!.\n",
      "-Following tools remained unaccounted for: {'nan'}. Please ensure if it is OK to skip these tools from the output.\n",
      "-Output JSON file generated & returned!.\n",
      " \n",
      "test/input/vid_short_1.mp4 has been successfully processed!.\n",
      "Surgtoolloc_det.predict() exited\n",
      " \n",
      "Surgtoolloc_det.process_case() exited.\n",
      "Surgtoolloc_det.save() entered\n",
      "-file saved\n",
      "Surgtoolloc_det.save() exited\n"
     ]
    }
   ],
   "source": [
    "!python -m process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14e4fe-3213-41f0-a351-6217eed974b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad5668-6f7b-4902-838d-7559d871e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.test_utils import show_install\n",
    "show_install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29502aa-6b6c-4581-839d-821c2439702c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
