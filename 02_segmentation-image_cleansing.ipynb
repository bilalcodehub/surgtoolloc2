{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222023a-d3f7-4307-bce4-b81ede30cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastcore.parallel import *\n",
    "from skimage.measure import label, regionprops, find_contours\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23df58-e80b-41b8-b935-b54698137c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=2022\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    #tf.set_random_seed(seed)\n",
    "seed_everything(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbadcef-8501-444c-9c56-d0187ed03b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vfs = get_files('data/video_clips')\n",
    "len(vfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7058cf-a51d-46a8-82fb-bb20e6cfb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(vf, n=1):\n",
    "\n",
    "    dst=Path().absolute()/'data/segmentation/images'\n",
    "    dst.mkdir(exist_ok=True)\n",
    "    \n",
    "    c=1 #number of frames to store\n",
    "    video=cv2.VideoCapture(str(Path().absolute()/vf))\n",
    "    \n",
    "    while(True):\n",
    "        ret,f=video.read()\n",
    "        if ret:\n",
    "            if c<=n: # already save n images so quit\n",
    "                if cv2.countNonZero(cv2.cvtColor(f,cv2.COLOR_BGR2GRAY))!=0: # frame is blank (black pixels only\n",
    "                    name=str(dst/f'{vf.stem}_{c:05}.jpg')\n",
    "                    cv2.imwrite(name,f)\n",
    "                    c+=1\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5f39e-67c8-4f18-930c-8772efaa5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time parallel(extract_images,vfs,n_workers=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e7d8b-25b2-4692-bbee-5a0d856f9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!prodigy image.manual binaryseg ./data/segmentation/images --label FOREGROUND --remove-base64 --width 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0968416c-ea61-43c8-9eda-8063fc7ccae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!prodigy db-out binaryseg > ./data/segmentation/binaryseg.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c131d743-8007-46be-a31d-bac2af9b9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"data/segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23d920-e983-42f4-a4c6-b413f21af81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [\"Background\", \"Foreground\"]\n",
    "\n",
    "def get_image_mask(fn):\n",
    "    f=Path(str(fn).replace('images', 'masks').replace('jpg','png'))\n",
    "    return PILMask.create(f) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31fa34-9b94-4ee0-ac14-78b3f68b3cdc",
   "metadata": {},
   "source": [
    "There are over 100 videos for which frames contain nothing but just black background, no surgical view or equipment. We had to ignore those files in the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be0d065-5be5-4446-916f-6b031b2d9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_data():\n",
    "    fs = get_image_files(path/'images')\n",
    "    for f in fs:\n",
    "        m = Path(str(f).replace('images', 'masks').replace('jpg','png'))\n",
    "        if not m.exists():\n",
    "            if os.path.exists(f):\n",
    "                os.remove(f)\n",
    "                print(f, ' removed successfully.')\n",
    "\n",
    "proc_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7b732-9fad-4614-8069-d1545e169acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(180,320)\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a430cd-cb70-40ae-b102-bbd8d39c67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(size, batch_size):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, MaskBlock(codes=codes)),\n",
    "                       get_items=get_image_files,\n",
    "                       get_y = get_image_mask,\n",
    "                       splitter=RandomSplitter(valid_pct=0.2),\n",
    "                       item_tfms=[Resize(size, ResizeMethod.Squish)],\n",
    "                       batch_tfms=[*aug_transforms(size=size,min_scale=1), \n",
    "                                   IntToFloatTensor(div_mask=255), \n",
    "                                   Normalize.from_stats(*imagenet_stats)])\n",
    "    return dblock.dataloaders(path/'images', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078aecc9-25e9-4d87-8569-2d5ee96f78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls=get_dls(size=size, batch_size=batch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70452f0-4581-4459-b83f-0d9e379efed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = dls.one_batch()\n",
    "xb[0].shape, type(xb[0]), yb[1].shape,type(yb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c370e-808c-46ce-b119-da6a39305d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(yb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76765fd-7661-4687-9dd2-8a2d20b4eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=5,nrows=2,vmin=1, vmax=30, figsize=(14,10),unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ac882-e9ea-4e11-a5fa-c00558480aaf",
   "metadata": {},
   "source": [
    "## Baseline learner with default loss and opt functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9234f-670a-4c6f-9468-992409384041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy(inp, targ):\n",
    "    targ = targ.squeeze(1)\n",
    "    return (inp.argmax(dim=1)==targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7cf217-67ee-4590-9860-a73f211f5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(dls,resnet34, self_attention=True, metrics=custom_accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359acfb4-bf6b-4a7a-9096-55c83bc651c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e91f6d-e272-45d8-81e9-ced5f6fc91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(12,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d299b-7e32-4892-b575-97c927c1a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(vmin=1, vmax=30, figsize=(14,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c4963-e812-41f7-8357-9cd1b754f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.path=Path('models/seg')\n",
    "learn.export('seg_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158cd8b-6747-4b1e-955a-c57d903c8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targs = learn.tta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107fb96b-fe5a-4e27-9b70-b838619a663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623bdfd-dbdf-4bad-80e1-62efa14d59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "PILMask.create(np.array(targs[5]*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27cade-5c88-4957-bd82-9ac3c9c827a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PILMask.create((np.array(preds[5].argmax(0))*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d62de0-28d0-47e6-802b-e53e1bdceafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = SegmentationInterpretation.from_learner(learn)\n",
    "losses,idxs = interp.top_losses()\n",
    "top_losses, top_idxs = interp.top_losses()\n",
    "\n",
    "interp.plot_top_losses(9, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42b3cf-f177-4e6f-9a1b-2b92619bdbee",
   "metadata": {},
   "source": [
    "## CrossEntropyFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358151c3-acd3-4959-8481-565b59ed5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(dls,resnet34, loss_func = CrossEntropyLossFlat(axis=1),self_attention=True, metrics=custom_accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cfadf4-eaf4-41be-8edb-2a026ffdd991",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0e363-adca-4bd2-98e3-e90c41f34397",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(12,1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8d724-82d9-4004-bad2-baeb6a40f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.path=Path('models/seg')\n",
    "learn.export('seg_celf_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c8a2b8-b6d5-49cf-b0e9-ce1836980339",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targs = learn.tta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d616b7-884e-4969-b974-33795cdee534",
   "metadata": {},
   "outputs": [],
   "source": [
    "PILMask.create(np.array(targs[2000]*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204d177-ac20-4b7d-9fb3-2967b534d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PILMask.create((np.array(preds[2000].argmax(0))*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b13f049-6c02-4ce5-9284-c1479cb47e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = SegmentationInterpretation.from_learner(learn)\n",
    "losses,idxs = interp.top_losses()\n",
    "top_losses, top_idxs = interp.top_losses()\n",
    "\n",
    "interp.plot_top_losses(9, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbafe60-4eaa-41c1-8a3f-e22306f33c76",
   "metadata": {},
   "source": [
    "## Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de2383-79f2-4c38-8d95-92a645a19f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ranger\n",
    "learn = unet_learner(dls,resnet34, loss_func = CrossEntropyLossFlat(axis=1),self_attention=True, act_cls=Mish, opt_func=opt, metrics=custom_accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cbc5cf-0f46-4acd-b9bf-2b94b4e788ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b2a97-f7c6-46c6-a4f3-5ce7f47fc315",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb09b5-ece3-41b8-98e6-beed6aa7df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_flat_cos(12, slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6f1a9-a352-45e6-89c4-10a9328deae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.path=Path('models/seg')\n",
    "learn.export('seg_ranger_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0440f-5a34-4800-abdb-65f05855acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PILMask.create(np.array(targs[2000]*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfc9c53-9ffb-49ad-901b-1040c53d9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "PILMask.create((np.array(preds[2000].argmax(0))*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2677a1-f890-4704-bf72-1823cb2b6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = SegmentationInterpretation.from_learner(learn)\n",
    "losses,idxs = interp.top_losses()\n",
    "top_losses, top_idxs = interp.top_losses()\n",
    "\n",
    "interp.plot_top_losses(9, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab47723-a3d7-429c-a268-50793a4b1bf9",
   "metadata": {},
   "source": [
    "# Using model for cropping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c765d32c-e9da-4fe2-a18d-90314be406e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp crop_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c624a3-130d-43f2-ae47-4417ba8ab803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import nb_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a113903-5465-412b-ad22-face32236886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2959ef1f-addb-42a3-b116-aeee1a81ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastai.vision.all import *\n",
    "from fastcore.parallel import *\n",
    "from skimage.measure import label, regionprops, find_contours\n",
    "from datetime import datetime\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ebd057-b270-4c83-864e-bfacded7bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "codes = [\"Background\", \"Foreground\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e8beb8-50c2-44e1-9946-afa4a9a6d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_image_mask(fn):\n",
    "    f=Path(str(fn).replace('images', 'masks').replace('jpg','png'))\n",
    "    return PILMask.create(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57350429-38b0-40a9-a4ad-1b7b77ed2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def custom_accuracy(inp, targ):\n",
    "    targ = targ.squeeze(1)\n",
    "    return (inp.argmax(dim=1)==targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d511962-6c77-4583-bce9-7acd16f62a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1933454"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = Path().absolute()/'data/train_images_orig'\n",
    "dst = Path().absolute()/'data/train_images_crop'\n",
    "dst.mkdir(exist_ok=True)\n",
    "\n",
    "fssrc=set([parent_label(f)+'/'+f.name for f in get_image_files(src)])\n",
    "fsdst=set([parent_label(f)+'/'+f.name for f in get_image_files(dst)])\n",
    "\n",
    "fsdelta =  L(fssrc - fsdst)\n",
    "len(fsdelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e038e4f5-c616-42f0-abaf-7c2e852f8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = L([src/f for f in fsdelta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a191032a-38d1-4224-80b4-1345f829aec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1933454,\n",
       " Path('/home/bilal/mlworks/surgtoolloc2/data/train_images_orig/clip_011547/01575.jpg'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fs),fs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d77e8d-f7b4-4410-8231-4176411dbb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def main():\n",
    "    # loading the best model\n",
    "    learn=load_learner('/home/bilal/mlworks/surgtoolloc2/models/seg/seg_v1.pkl', cpu=False)\n",
    "\n",
    "    # define src and dst folders\n",
    "    src = Path().absolute()/'data/train_images_orig'\n",
    "    dst = Path().absolute()/'data/train_images_crop'\n",
    "    dst.mkdir(exist_ok=True)\n",
    "\n",
    "    fssrc=set([parent_label(f)+'/'+f.name for f in get_image_files(src)])\n",
    "    fsdst=set([parent_label(f)+'/'+f.name for f in get_image_files(dst)])\n",
    "\n",
    "    fsdelta =  L(fssrc - fsdst)\n",
    "    \n",
    "    fs = L([src/f for f in fsdelta])\n",
    "\n",
    "    # creating bunches for processing images\n",
    "    bunches = [i for i in range(len(fs)) if i%50000==0]\n",
    "\n",
    "    # for each bunch of images, predict masks and then use it to crop images and save them in the folder\n",
    "    for i in range(len(bunches)):\n",
    "        # setting start and end of a batch\n",
    "        start=bunches[i]\n",
    "        if not (i==len(bunches)-1):\n",
    "            if bunches[i]==bunches[i+1]:\n",
    "                end = len(bunches)\n",
    "            else:\n",
    "                end=bunches[i+1]\n",
    "        else:\n",
    "            end=len(fs)\n",
    "\n",
    "        print(\"-Start Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "        print(f'-Predicting masks for images: {start} -> {end}.')\n",
    "        preds,_ = learn.get_preds(dl=learn.dls.test_dl(fs[start:end]))\n",
    "\n",
    "        print(f'-Cropping and saving images: {start} -> {end}.')\n",
    "\n",
    "        # for p, f in zip(preds,fs[start:end]):\n",
    "        for p, f in zip(preds,learn.dl.items):\n",
    "            dst_clip = dst/parent_label(f)\n",
    "            dst_clip.mkdir(exist_ok=True)\n",
    "\n",
    "            fn = f.name\n",
    "\n",
    "            im=PILImage.create(f)\n",
    "            (h,w)=im.shape\n",
    "            # (h,w)=(640,512)\n",
    "            mask=PILMask.create((np.array(p.argmax(0))*255).astype(np.uint8))\n",
    "            mask=Resize((h,w), ResizeMethod.Squish) (mask)\n",
    "\n",
    "            lbl = label(np.array(mask))\n",
    "            props = regionprops(lbl)\n",
    "            x1,y1,x2,y2=props[0].bbox[0],props[0].bbox[2],props[0].bbox[1],props[0].bbox[3]\n",
    "\n",
    "            im_c = PILImage.create(np.array(im)[x1:y1,x2:y2])\n",
    "            im_c.save(dst_clip/fn)\n",
    "\n",
    "        print(\"-End Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568e011-e72b-4fd0-9d21-89f1b6ddd0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d0b2a4c-7608-4c4e-b896-92698d748630",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_export('02_segmentation-image_cleansing.ipynb', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e0f27-8a93-484a-8ad9-189e21907b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(get_image_files(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c92f9-4000-4b6b-942a-f2c7f4a5f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(get_image_files(dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d5433-1fd5-4926-84b9-63334c198b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(get_image_files(src))==len(get_image_files(dst)), 'Not all images are cropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32c2cb-e7da-4aa0-b4cc-c200653aa6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
